{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5d4066",
   "metadata": {},
   "source": [
    "# YouTube Comments Data Preprocessing and Cleaning\n",
    "\n",
    "This notebook performs data cleaning, preprocessing, and duplicate tagging for YouTube comments, preparing the data for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df82e53",
   "metadata": {},
   "source": [
    "### Import Required Libraries and Set Display Options\n",
    "\n",
    "This cell imports all necessary libraries for data manipulation, text processing, and visualization. It also sets pandas display options and configures warnings to be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3970aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "import contractions\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# # Download required NLTK resources (only first time)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm integration with pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show full text without truncation\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5475f55",
   "metadata": {},
   "source": [
    "### Load and Inspect Cleaned Comments Dataset\n",
    "\n",
    "This cell loads the cleaned comments dataset from a CSV file and displays its structure using `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006e744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4724755 entries, 0 to 4724754\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   commentId        int64  \n",
      " 1   channelId        int64  \n",
      " 2   videoId          int64  \n",
      " 3   authorId         int64  \n",
      " 4   textOriginal     object \n",
      " 5   parentCommentId  float64\n",
      " 6   likeCount        int64  \n",
      " 7   publishedAt      object \n",
      " 8   updatedAt        object \n",
      "dtypes: float64(1), int64(5), object(3)\n",
      "memory usage: 324.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reading the cleaned comments dataset\n",
    "df = pd.read_csv('dataset/comments_all_cleaned.csv')\n",
    "\n",
    "# Displaying the DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83365231",
   "metadata": {},
   "source": [
    "### Load Irrelevant Video IDs\n",
    "\n",
    "This cell loads a list of irrelevant video IDs from a CSV file, which will be used to filter out unwanted comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848566cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a CSV file containing irrelevant video IDs into a DataFrame\n",
    "irrelevant = pd.read_csv('dataset/irrelevant_video_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870f522",
   "metadata": {},
   "source": [
    "### Filter Out Irrelevant Videos\n",
    "\n",
    "This cell removes comments associated with irrelevant video IDs from the main DataFrame, resulting in a filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out irrelevant videos from the dataframe\n",
    "video_ids_to_drop = irrelevant.iloc[:, 0].unique()\n",
    "df_filtered = df[~df['videoId'].isin(video_ids_to_drop)]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3247a512",
   "metadata": {},
   "source": [
    "### Convert Published Date to Datetime\n",
    "\n",
    "This cell converts the `publishedAt` column in the filtered DataFrame to datetime objects for easier sorting and time-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93889be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the 'publishedAt' column in the df_filtered DataFrame to datetime objects.\n",
    "df_filtered['publishedAt'] = pd.to_datetime(df_filtered['publishedAt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09378c",
   "metadata": {},
   "source": [
    "### Sort Comments by Published Date\n",
    "\n",
    "This cell sorts the filtered DataFrame by the `publishedAt` column in ascending order, ensuring chronological order for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame in place by the 'publishedAt' column in ascending order\n",
    "df_filtered.sort_values(by='publishedAt', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac16c9",
   "metadata": {},
   "source": [
    "### Flag Duplicate Comments\n",
    "\n",
    "This cell creates a `duplicatedFlag` column to identify exact duplicate comments (based on `videoId`, `authorId`, and `textOriginal`). The first occurrence is flagged as 0, and subsequent duplicates as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71e4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duplicatedFlag\n",
       "0    4644162\n",
       "1      80593\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A flag value of 0 indicates the first occurrence of the comment, and 1 indicates a duplicate\n",
    "df_filtered[\"duplicatedFlag\"] = df_filtered.duplicated(\n",
    "    subset=[\"videoId\", \"authorId\", \"textOriginal\"],\n",
    "    keep=\"first\"   # first occurrence = 0, rest = 1\n",
    ").astype(int)\n",
    "df_filtered[\"duplicatedFlag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc98933",
   "metadata": {},
   "source": [
    "### Initialize Lemmatizer and Stopwords\n",
    "\n",
    "This cell initializes the NLTK WordNet lemmatizer and the set of English stopwords, keeping negation words for more accurate text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer and stop words for text processing.\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"nor\"}  # keep negations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b385f",
   "metadata": {},
   "source": [
    "### Define Text Cleaning Function\n",
    "\n",
    "This cell defines the `clean_text` function, which performs several preprocessing steps on comment text: lowercasing, expanding contractions, removing mentions, hashtags, links, emojis, punctuation, normalizing elongated words, collapsing whitespace, tokenizing, removing stopwords, and lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text for subsequent ML models \n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase & trim\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Expand contractions (\"can't\" -> \"cannot\")\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # Remove mentions, hashtags, links\n",
    "    text = re.sub(r'@[A-Za-z0-9_.-]+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", '', text)\n",
    "\n",
    "    # Remove emojis completely\n",
    "    text = ''.join(ch for ch in text if not emoji.is_emoji(ch))\n",
    "\n",
    "    # Remove punctuation (ASCII + Unicode)\n",
    "    text = ''.join(ch for ch in text if not unicodedata.category(ch).startswith(\"P\"))\n",
    "\n",
    "    # Normalize elongated words (\"soooo\" -> \"soo\")\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "    # Collapse whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords & lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4b782",
   "metadata": {},
   "source": [
    "### Clean Comments and Create New Column\n",
    "\n",
    "This cell applies the `clean_text` function to the `textOriginal` column of the filtered DataFrame, creating a new column `cleanedText` with the processed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bde71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4724755/4724755 [14:11<00:00, 5546.56it/s] \n",
      "100%|██████████| 4724755/4724755 [21:22<00:00, 3682.81it/s] \n"
     ]
    }
   ],
   "source": [
    "# Applies the `clean_text` function to the `textOriginal` column of the `df_filtered` DataFrame,\n",
    "# creating a new column `cleanedText` with the processed text. The `progress_apply` method is used to show a\n",
    "# progress bar for the operation.\n",
    "\n",
    "df_filtered['cleanedText'] = df_filtered['textOriginal'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d44c5",
   "metadata": {},
   "source": [
    "### Tag Exact Duplicates of Cleaned Text\n",
    "\n",
    "This cell sorts the DataFrame by published date and tags exact duplicates of the `cleanedText` column, updating the `duplicatedFlag` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c0cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duplicatedFlag\n",
       "0    4614143\n",
       "1     110612\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame in place by the \"publishedAt\" column in ascending order\n",
    "df_filtered.sort_values(by=\"publishedAt\", inplace=True)\n",
    "\n",
    "# For rows where duplicatedFlag == 0, check duplicates by the subset\n",
    "mask = df_filtered[\"duplicatedFlag\"] == 0\n",
    "\n",
    "# Mark all but the first (earliest) occurrence as 1\n",
    "df_filtered.loc[mask, \"duplicatedFlag\"] = (\n",
    "    df_filtered[mask].duplicated(subset=[\"videoId\", \"authorId\", \"cleanedText\"], keep=\"first\").astype(int)\n",
    ")\n",
    "\n",
    "# Display the count of unique values in the \"duplicatedFlag\" column\n",
    "df_filtered[\"duplicatedFlag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46630008",
   "metadata": {},
   "source": [
    "### Inspect a Sample Duplicate Comment\n",
    "\n",
    "This cell filters the DataFrame for rows flagged as duplicates and displays a random sample for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4642d384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>cleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4689347</th>\n",
       "      <td>44543</td>\n",
       "      <td>773251</td>\n",
       "      <td>Thank you dear 😘 Please share 💗 💕 ❤️</td>\n",
       "      <td>thank dear please share ️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         videoId  authorId                          textOriginal  \\\n",
       "4689347    44543    773251  Thank you dear 😘 Please share 💗 💕 ❤️   \n",
       "\n",
       "                       cleanedText  \n",
       "4689347  thank dear please share ️  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters the DataFrame for rows where 'duplicatedFlag' is 1 and then selects a random sample of 1 from the filtered data\n",
    "df_filtered.loc[df_filtered['duplicatedFlag'] == 1, ['videoId', 'authorId', 'textOriginal','cleanedText']].sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09188eb1",
   "metadata": {},
   "source": [
    "### Save Processed Data to CSV\n",
    "\n",
    "This cell exports the filtered and processed DataFrame to a CSV file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc784b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code exports the filtered DataFrame to a CSV file, excluding the index column.\n",
    "df_filtered.to_csv('dataset/comments_all_tagged_text_duplicates.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
